import re
import os
import time
import json
import logging
import base64
import socket
import random
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Optional, Set, Union
import requests
from bs4 import BeautifulSoup
import yaml
from urllib.parse import urlencode, quote, unquote, urlparse, urlunparse

# Import custom modules
# Assuming config.py and config_validator.py exist in the same directory (src/)
try:
    from config import ProxyConfig, ChannelConfig
    from config_validator import ConfigValidator
except ImportError:
    # Fallback for standalone execution or testing without full project structure
    # Define dummy classes or raise an error if critical for functionality
    print("Error: Required modules (config.py, config_validator.py) not found.")
    print("Please ensure these files are in the same directory or accessible via PYTHONPATH.")
    # For now, we will exit or define minimal dummy classes to allow syntax check
    # In a real scenario, this would likely be an unrecoverable error.
    class ProxyConfig:
        def __init__(self):
            self.MAX_RETRIES = 3
            self.RETRY_DELAY = 5
            self.REQUEST_TIMEOUT = 30
            self.MIN_CONFIGS_PER_CHANNEL = 1
            self.MAX_CONFIG_AGE_DAYS = 7
            self.use_maximum_power = False
            self.specific_config_count = 50
            self.OUTPUT_FILE = 'configs/proxy_configs.txt'
            self.STATS_FILE = 'configs/channel_stats.json'
            self.HEADERS = {'User-Agent': 'Mozilla/5.0'}
            self.SOURCE_URLS = []
            self.SUPPORTED_PROTOCOLS = {
                "vless://": {"priority": 2, "aliases": [], "enabled": True},
                "vmess://": {"priority": 1, "aliases": [], "enabled": True},
                "ss://": {"priority": 2, "aliases": [], "enabled": True},
                "trojan://": {"priority": 2, "aliases": [], "enabled": True},
                "hysteria2://": {"priority": 2, "aliases": ["hy2://"], "enabled": True},
                "tuic://": {"priority": 1, "aliases": [], "enabled": True},
                "wireguard://": {"priority": 1, "aliases": [], "enabled": False}, # Default to False if not specified
                "ssr://": {"priority": 2, "aliases": [], "enabled": True},
                "hysteria://": {"priority": 2, "aliases": [], "enabled": True},
                "snell://": {"priority": 2, "aliases": [], "enabled": True},
                "ssh://": {"priority": 1, "aliases": [], "enabled": True},
                "mieru://": {"priority": 2, "aliases": [], "enabled": True},
                "anytls://": {"priority": 2, "aliases": [], "enabled": True},
                "warp://": {"priority": 1, "aliases": [], "enabled": True},
                "juicity://": {"priority": 2, "aliases": [], "enabled": True},
            }
        def get_enabled_channels(self): return []
        def is_protocol_enabled(self, protocol): return self.SUPPORTED_PROTOCOLS.get(protocol, {}).get("enabled", False)
        def update_channel_stats(self, channel, success, response_time=0): pass # Dummy
    
    class ChannelConfig:
        def __init__(self, url):
            self.url = url
            self.enabled = True
            self.is_telegram = 't.me/s' in url
            self.metrics = self.DummyMetrics()
        class DummyMetrics:
            total_configs = 0
            valid_configs = 0
            unique_configs = 0
            avg_response_time = 0
            last_success_time = None
            fail_count = 0
            success_count = 0
            overall_score = 0.0
            protocol_counts = {}
        def calculate_overall_score(self): pass # Dummy

    class ConfigValidator:
        @staticmethod
        def is_base64(s): return True # Simplified for dummy
        @staticmethod
        def decode_base64_text(s): return s # Simplified for dummy
        @staticmethod
        def clean_vmess_config(s): return s # Simplified for dummy
        @staticmethod
        def normalize_hysteria2_protocol(s): return s # Simplified for dummy
        @staticmethod
        def check_base64_content(s): return s # Simplified for dummy
        @staticmethod
        def split_configs(s): return s.split('\n') # Simplified for dummy
        @staticmethod
        def clean_config(s): return s # Simplified for dummy
        @staticmethod
        def validate_protocol_config(config_str, protocol): return True # Simplified for dummy

# Configure logging for better debugging and information
logging.basicConfig(
    level=logging.INFO, # Set logging level to INFO
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('proxy_fetcher.log'), # Log to file
        logging.StreamHandler() # Log to console
    ]
)
logger = logging.getLogger(__name__)

class ClashConverter:
    """
    ฺฉูุงุณ ฺฉูฺฉ ุจุฑุง ุชุจุฏู ุฏฺฉุดูุฑโูุง ูพฺฉุฑุจูุฏ Clash ุจู ูุฑูุช URI ูพุฑูฺฉุณ ูุฑุจูุทู.
    ุงู ฺฉูุงุณ ุจุฑุง ุงุณุชุฎุฑุงุฌ ูพฺฉุฑุจูุฏโูุง ุงุฒ ูุงูโูุง Clash YAML ู ุชุจุฏู ุขูโูุง
    ุจู ูุฑูุชโูุง ุงุณุชุงูุฏุงุฑุฏ URI ฺฉู ูโุชูุงููุฏ ูพุฑุฏุงุฒุด ุดููุฏุ ุงุณุชูุงุฏู ูโุดูุฏ.
    """
    @staticmethod
    def to_uri(proxy: Dict) -> Optional[str]:
        """
        ฺฉ ุฏฺฉุดูุฑ ูพฺฉุฑุจูุฏ ูพุฑูฺฉุณ Clash ุฑุง ุจู ูุฑูุช URI ูุฑุจูุทู ุชุจุฏู ูโฺฉูุฏ.
        """
        proxy_type = proxy.get("type")
        converters = {
            "vless": ClashConverter.to_vless,
            "vmess": ClashConverter.to_vmess,
            "ss": ClashConverter.to_ss,
            "trojan": ClashConverter.to_trojan,
            "ssr": ClashConverter.to_ssr,
            "hysteria": ClashConverter.to_hysteria, # Added Hysteria
            "hysteria2": ClashConverter.to_hysteria2,
            "tuic": ClashConverter.to_tuic,
            "wireguard": ClashConverter.to_wireguard,
            "anytls": ClashConverter.to_anytls,
            "snell": ClashConverter.to_snell, # Added Snell
            "ssh": ClashConverter.to_ssh, # Added SSH
            "mieru": ClashConverter.to_mieru, # Added Mieru
            "juicity": ClashConverter.to_juicity, # Added Juicity
        }
        if proxy_type in converters:
            try:
                return converters[proxy_type](proxy)
            except Exception as e:
                logger.error(f"Error converting Clash proxy to URI for type '{proxy_type}': {e}")
                return None
        else:
            logger.debug(f"[SKIPPED_CLASH] Unsupported Clash proxy type for URI conversion: '{proxy_type}'")
        return None

    @staticmethod
    def to_vless(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash VLESS ุจู URI VLESS."""
        server, port, uuid = proxy.get("server", ""), proxy.get("port", ""), proxy.get("uuid", "")
        name = quote(proxy.get("name", ""), safe='') # Ensure name is URL-safe
        
        params = {
            "type": proxy.get("network", "tcp"), # Default to tcp
            "security": "none",
            "flow": proxy.get("flow"),
        }

        # TLS/Reality settings
        if proxy.get("tls"):
            if proxy.get("reality-opts"):
                params["security"] = "reality"
                params["pbk"] = proxy["reality-opts"].get("public-key")
                params["sid"] = proxy["reality-opts"].get("short-id")
                params["fp"] = proxy.get("client-fingerprint") # Reality needs client-fingerprint
                if proxy["reality-opts"].get("spiderx"): params["spx"] = proxy["reality-opts"]["spiderx"]
                if proxy["reality-opts"].get("dest"): params["dest"] = proxy["reality-opts"]["dest"]
            else:
                params["security"] = "tls"
                params["sni"] = proxy.get("servername")
                if proxy.get("alpn"): params["alpn"] = ",".join(proxy["alpn"])
                if proxy.get("client-fingerprint"): params["fp"] = proxy["client-fingerprint"]
                if proxy.get("skip-cert-verify"): params["allowinsecure"] = "1"
        
        # Network specific options
        if params["type"] == "ws":
            ws_opts = proxy.get("ws-opts", {})
            params["path"] = ws_opts.get("path", "/")
            params["host"] = ws_opts.get("headers", {}).get("Host")
            if ws_opts.get("max-early-data"): params["ed"] = str(ws_opts["max-early-data"])
        elif params["type"] == "grpc":
            grpc_opts = proxy.get("grpc-opts", {})
            params["serviceName"] = grpc_opts.get("grpc-service-name")
            if grpc_opts.get("xver"): params["xver"] = str(grpc_opts["xver"])
        elif params["type"] == "http": # for direct http (rare for Vless)
            http_opts = proxy.get("http-opts", {})
            if http_opts.get("path"): params["path"] = http_opts["path"][0] # Take first path
            if http_opts.get("headers") and http_opts["headers"].get("Host"):
                params["host"] = http_opts["headers"]["Host"][0]

        # Clean up None values and encode
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"vless://{uuid}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_vmess(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash VMess ุจู URI VMess."""
        name = proxy.get("name", "")
        vmess_json = {
            "v": "2", # VMess protocol version
            "ps": name, # Profile Name
            "add": proxy.get("server"), # Server address
            "port": str(proxy.get("port")), # Server port (as string)
            "id": proxy.get("uuid"), # UUID
            "aid": str(proxy.get("alterId", 0)), # AlterId (as string)
            "net": proxy.get("network", "tcp"), # Network type (tcp, ws, http, quic, grpc)
            "type": "none", # Header type (none, http, srtp, utp, wechat-video, dtls, wireguard) - default none
            "host": "", # Host header for HTTP/WS
            "path": "", # Path for WS/HTTP/gRPC
            "tls": "", # "tls" if TLS enabled
            "sni": "", # Server Name Indication
            "fp": "", # Fingerprint
            "scy": proxy.get("cipher", "auto"), # Security cipher (auto, aes-128-gcm, chacha20-poly1305, none)
            "alpn": [], # ALPN for TLS
            "xver": "1", # gRPC Xver
            # Reality options for VMess
            "pbk": "",
            "sid": "",
            "spx": "",
            "dest": "",
        }

        # Network specific options
        if vmess_json["net"] == "ws":
            ws_opts = proxy.get("ws-opts", {})
            vmess_json["path"] = ws_opts.get("path", "/")
            vmess_json["host"] = ws_opts.get("headers", {}).get("Host")
        elif vmess_json["net"] == "h2":
            h2_opts = proxy.get("h2-opts", {})
            if h2_opts.get("host"): vmess_json["host"] = h2_opts["host"][0]
            if h2_opts.get("path"): vmess_json["path"] = h2_opts["path"]
        elif vmess_json["net"] == "grpc":
            grpc_opts = proxy.get("grpc-opts", {})
            vmess_json["path"] = grpc_opts.get("grpc-service-name")
            if grpc_opts.get("xver"): vmess_json["xver"] = str(grpc_opts["xver"])

        # TLS settings
        if proxy.get("tls"):
            vmess_json["tls"] = "tls"
            vmess_json["sni"] = proxy.get("servername")
            if proxy.get("client-fingerprint"): vmess_json["fp"] = proxy["client-fingerprint"]
            if proxy.get("alpn"): vmess_json["alpn"] = proxy["alpn"]
            if proxy.get("skip-cert-verify"): vmess_json["allowInsecure"] = 1

            # Reality settings for VMess (if applicable)
            if proxy.get("reality-opts"):
                vmess_json["tls"] = "reality" # Overwrite tls to reality
                reality_opts = proxy["reality-opts"]
                vmess_json["pbk"] = reality_opts.get("public-key", "")
                vmess_json["sid"] = reality_opts.get("short-id", "")
                vmess_json["spx"] = reality_opts.get("spiderx", "")
                vmess_json["dest"] = reality_opts.get("dest", "")
        
        # Remove empty or default values to keep JSON compact
        final_vmess_json = {k: v for k, v in vmess_json.items() if v != "" and v != "none" and v != "0" and v != []}
        
        # Special handling for "aid": 0 and "xver": "1" if they are explicit defaults
        if proxy.get("alterId", 0) == 0 and "aid" not in final_vmess_json:
            final_vmess_json["aid"] = "0"
        if proxy.get("grpc-opts", {}).get("xver", "1") == "1" and "xver" not in final_vmess_json:
            final_vmess_json["xver"] = "1"

        json_str = json.dumps(final_vmess_json, separators=(',', ':')).encode('utf-8')
        return f"vmess://{base64.b64encode(json_str).decode('utf-8')}"

    @staticmethod
    def to_ss(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash SS ุจู URI SS."""
        server, port, password, cipher = proxy.get("server", ""), proxy.get("port", ""), proxy.get("password", ""), proxy.get("cipher", "")
        name = quote(proxy.get("name", ""), safe='')

        user_info = f"{cipher}:{password}"
        plugin_opts_str = ""

        if "plugin" in proxy:
            plugin_params = {"plugin": proxy["plugin"]}
            plugin_opts = proxy.get("plugin-opts", {})

            if proxy["plugin"] == "obfs":
                plugin_params["obfs"] = plugin_opts.get("mode")
                plugin_params["obfs-host"] = plugin_opts.get("host")
            elif proxy["plugin"] == "v2ray-plugin":
                plugin_params["mode"] = plugin_opts.get("mode", "websocket")
                if plugin_opts.get("tls"): plugin_params["tls"] = "true"
                plugin_params["path"] = plugin_opts.get("path")
                plugin_params["host"] = plugin_opts.get("host")
                if plugin_opts.get("mux"): plugin_params["mux"] = "true"
                if plugin_opts.get("client-fingerprint"): plugin_params["fp"] = plugin_opts["client-fingerprint"]
                if plugin_opts.get("servername"): plugin_params["sni"] = plugin_opts["servername"]
            elif proxy["plugin"] == "shadow-tls":
                plugin_params["password"] = plugin_opts.get("password")
                if plugin_opts.get("version"): plugin_params["version"] = str(plugin_opts["version"])
                if plugin_opts.get("server_name"): plugin_params["host"] = plugin_opts["server_name"] # Map to 'host' for URI

            plugin_params = {k: v for k, v in plugin_params.items() if v is not None and v != ''}
            if plugin_params:
                plugin_opts_str = "?" + urlencode(plugin_params, quote_via=quote)
        
        # Base64 encode user_info for some SS clients/formats if needed, but not standard for Clash output to URI
        # Sticking to plain for direct SS URI
        return f"ss://{quote(user_info)}@{server}:{port}{plugin_opts_str}#{name}"

    @staticmethod
    def to_trojan(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash Trojan ุจู URI Trojan."""
        server, port, password = proxy.get("server", ""), proxy.get("port", ""), proxy.get("password", "")
        name = quote(proxy.get("name", ""), safe='')

        params = {}
        # TLS settings
        if proxy.get("tls"):
            params["security"] = "tls"
            params["sni"] = proxy.get("servername")
            if proxy.get("alpn"): params["alpn"] = ",".join(proxy["alpn"])
            if proxy.get("client-fingerprint"): params["fp"] = proxy["client-fingerprint"]
            if proxy.get("skip-cert-verify"): params["allowinsecure"] = "1"
        
        # Reality settings for Trojan (if applicable)
        if proxy.get("reality-opts"):
            params["security"] = "reality"
            reality_opts = proxy["reality-opts"]
            params["pbk"] = reality_opts.get("public-key", "")
            params["sid"] = reality_opts.get("short-id", "")
            params["fp"] = proxy.get("client-fingerprint", "chrome") # Ensure default fp for reality
            if reality_opts.get("spiderx"): params["spx"] = reality_opts["spiderx"]
            if reality_opts.get("dest"): params["dest"] = reality_opts["dest"]

        # Network type
        network = proxy.get("network", "tcp")
        params["type"] = network

        # Network specific options
        if network == "ws":
            ws_opts = proxy.get("ws-opts", {})
            params["path"] = ws_opts.get("path", "/")
            params["host"] = ws_opts.get("headers", {}).get("Host")
            if ws_opts.get("max-early-data"): params["ed"] = str(ws_opts["max-early-data"])
        elif network == "grpc":
            grpc_opts = proxy.get("grpc-opts", {})
            params["serviceName"] = grpc_opts.get("grpc-service-name")
        elif network == "http": # Direct HTTP
            http_opts = proxy.get("http-opts", {})
            if http_opts.get("path"): params["path"] = http_opts["path"][0]
            if http_opts.get("headers") and http_opts["headers"].get("Host"):
                params["host"] = http_opts["headers"]["Host"][0]
        elif network == "tcp" and proxy.get("tcp-opts", {}).get("header", {}).get("type") == "http":
            tcp_header_opts = proxy["tcp-opts"]["header"]
            if tcp_header_opts.get("request", {}).get("path"):
                params["path"] = tcp_header_opts["request"]["path"][0] # Take first path
            if tcp_header_opts.get("request", {}).get("headers", {}).get("Host"):
                params["host"] = tcp_header_opts["request"]["headers"]["Host"][0]
            params["headerType"] = "http" # Indicate HTTP header type

        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"trojan://{quote(password)}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_hysteria(proxy: dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash Hysteria ุจู URI Hysteria."""
        server, port = proxy.get("server", ""), proxy.get("port", "")
        auth_str = proxy.get("auth-str", "")
        name = quote(proxy.get("name", ""), safe='')

        params = {
            "auth": auth_str,
            "upmbps": proxy.get("up"),
            "downmbps": proxy.get("down"),
            "protocol": proxy.get("protocol"),
            "sni": proxy.get("sni"),
            "insecure": "1" if proxy.get("skip-cert-verify") else None,
            "peer": proxy.get("sni"), # Often peer is same as SNI for Hysteria
            "obfs": proxy.get("obfs"),
            "obfs-password": proxy.get("obfs-password"),
            "alpn": ",".join(proxy["alpn"]) if proxy.get("alpn") else None,
            "fp": proxy.get("fingerprint"),
        }
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"hysteria://{server}:{port}?{query_string}#{name}"


    @staticmethod
    def to_hysteria2(proxy: dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash Hysteria2 ุจู URI Hysteria2."""
        server, port, password = proxy.get("server", ""), proxy.get("port", ""), proxy.get("password", "")
        name = quote(proxy.get("name", ""), safe='')

        params = {
            "sni": proxy.get("sni"),
            "insecure": "1" if proxy.get("skip-cert-verify") else None,
            "pinSHA256": proxy.get("fingerprint"), # H2 uses pinSHA256
            "obfs": proxy.get("obfs"),
            "obfs-password": proxy.get("obfs-password"),
            "alpn": ",".join(proxy["alpn"]) if proxy.get("alpn") else None,
        }
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"hysteria2://{quote(password)}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_tuic(proxy: dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash TUIC ุจู URI TUIC."""
        server, port = proxy.get("server", ""), proxy.get("port", "")
        name = quote(proxy.get("name", ""), safe='')

        # Authentication can be UUID:Password or just token (password field)
        auth_part = ""
        if proxy.get("uuid") and proxy.get("password"):
            auth_part = f"{proxy['uuid']}:{quote(proxy['password'])}"
        elif proxy.get("token"): # For TUIC v5 with token
            auth_part = quote(proxy["token"])
        elif proxy.get("password"): # Older TUIC versions might use password as token
             auth_part = quote(proxy["password"])

        params = {
            "sni": proxy.get("sni"),
            "alpn": ",".join(proxy["alpn"]) if proxy.get("alpn") else None,
            "insecure": "1" if proxy.get("skip-cert-verify") else None,
            "udp_relay_mode": proxy.get("udp-relay-mode"),
            "congestion_control": proxy.get("congestion-control"),
            "disable_sni": "1" if proxy.get("disable-sni") else None,
            "multiplex": "1" if proxy.get("enable-multiplex") else None,
            "fp": proxy.get("fingerprint"),
            "version": proxy.get("version"), # TUIC protocol version
        }
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"tuic://{auth_part}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_ssr(proxy: dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash SSR ุจู URI SSR."""
        password_b64 = base64.b64encode(str(proxy.get('password', '')).encode('utf-8')).decode('utf-8').rstrip("=")
        
        # Assemble main SSR parts
        parts = [
            proxy.get('server', ''),
            str(proxy.get('port', '')),
            proxy.get('protocol', ''),
            proxy.get('cipher', ''),
            proxy.get('obfs', ''),
            password_b64 # Base64 encoded password
        ]
        main_part = ":".join(map(str, parts))

        # Assemble query parameters, base64 encode their values
        params = {}
        if proxy.get('obfs-param'):
            params["obfsparam"] = base64.b64encode(str(proxy['obfs-param']).encode('utf-8')).decode('utf-8').rstrip("=")
        if proxy.get('protocol-param'):
            params["protoparam"] = base64.b64encode(str(proxy['protocol-param']).encode('utf-8')).decode('utf-8').rstrip("=")
        if proxy.get('name'):
            params["remarks"] = base64.b64encode(str(proxy['name']).encode('utf-8')).decode('utf-8').rstrip("=")
        # Add other potential SSR params if they exist in Clash config
        if proxy.get('group'):
             params["group"] = base64.b64encode(str(proxy['group']).encode('utf-8')).decode('utf-8').rstrip("=")

        query_string = urlencode({k: v for k, v in params.items() if v}, quote_via=quote)
        
        # Combine and base64 encode the final SSR URI string
        full_ssr_string = f"{main_part}/?{query_string}" if query_string else main_part
        return f"ssr://{base64.b64encode(full_ssr_string.encode('utf-8')).decode('utf-8').rstrip('=')}"


    @staticmethod
    def to_wireguard(proxy: dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash WireGuard ุจู URI WireGuard."""
        private_key = quote(proxy.get('private-key', ''), safe='')
        server, port = proxy.get('server', ''), proxy.get('port', '')
        name = quote(proxy.get('name', ''), safe='')

        params = {
            'publicKey': proxy.get('public-key', ''),
            'presharedKey': proxy.get('pre-shared-key', ''),
            'mtu': str(proxy.get('mtu')) if proxy.get('mtu') else None,
        }
        
        # Handle IP addresses (local client IP)
        addresses = []
        if proxy.get('ip'): addresses.append(proxy['ip'])
        if proxy.get('ipv6'): addresses.append(proxy['ipv6'])
        if addresses: params['address'] = ",".join(addresses)

        # Handle DNS servers
        if proxy.get('dns'): params['dns'] = ",".join(proxy['dns'])

        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"wireguard://{private_key}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_anytls(proxy: dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash Anytls ุจู URI Anytls."""
        password, server, port = proxy.get('password', ''), proxy.get('server', ''), proxy.get('port', '')
        name = quote(proxy.get('name', ''), safe='')
        
        params = {
            'sni': proxy.get('sni'),
            'fp': proxy.get('client-fingerprint'),
            'alpn': ",".join(proxy["alpn"]) if proxy.get("alpn") else None,
            'insecure': "1" if proxy.get('skip-cert-verify') else None,
            'version': str(proxy.get('version')) if proxy.get('version') else None, # Anytls version
        }
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"anytls://{quote(password)}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_snell(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash Snell ุจู URI Snell."""
        server, port, psk = proxy.get("server", ""), proxy.get("port", ""), proxy.get("psk", "")
        name = quote(proxy.get("name", ""), safe='')

        params = {
            "version": str(proxy.get("version", 3)),
        }
        if proxy.get("obfs"):
            params["obfs"] = proxy["obfs"]
            if proxy.get("obfs-host"):
                params["obfs-host"] = proxy["obfs-host"]

        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"snell://{quote(psk)}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_ssh(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash SSH ุจู URI SSH."""
        server, port = proxy.get("server", ""), proxy.get("port", "")
        username = quote(proxy.get("username", ""), safe='')
        password = quote(proxy.get("password", ""), safe='') if proxy.get("password") else None
        name = quote(proxy.get("name", ""), safe='')
        
        # URI structure for SSH is ssh://[user:pass@]host:port[?params]#name
        user_pass_part = ""
        if username:
            user_pass_part = username
            if password:
                user_pass_part += f":{password}"
            user_pass_part += "@"

        params = {
            "key-path": proxy.get("key-path"),
            "key-passphrase": proxy.get("key-passphrase"),
            "host-key": proxy.get("host-key"),
            "fingerprint": proxy.get("fingerprint"),
            "udp-over-tcp": "1" if proxy.get("udp-over-tcp") else None,
        }
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)

        return f"ssh://{user_pass_part}{server}:{port}?{query_string}#{name}"
    
    @staticmethod
    def to_mieru(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash Mieru ุจู URI Mieru."""
        server, port = proxy.get("server", ""), proxy.get("port", "")
        uuid = quote(proxy.get("username", ""), safe='') # Mieru typically uses UUID as username
        name = quote(proxy.get("name", ""), safe='')

        params = {
            "password": quote(proxy.get("password", ""), safe=''),
            "transport": proxy.get("transport"),
            "multiplexing": proxy.get("multiplexing"),
            "security": proxy.get("tls"), # If 'tls' is boolean, map to 'security=tls'
            "sni": proxy.get("sni"),
            "fp": proxy.get("fingerprint"),
            "insecure": "1" if proxy.get("skip-cert-verify") else None,
        }
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"mieru://{uuid}@{server}:{port}?{query_string}#{name}"

    @staticmethod
    def to_juicity(proxy: Dict) -> str:
        """ุชุจุฏู ุฏฺฉุดูุฑ Clash Juicity ุจู URI Juicity."""
        server, port = proxy.get("server", ""), proxy.get("port", "")
        uuid = quote(proxy.get("uuid", ""), safe='')
        name = quote(proxy.get("name", ""), safe='')

        params = {
            "password": quote(proxy.get("password", ""), safe=''),
            "congestion_control": proxy.get("congestion-control"),
            "security": proxy.get("tls"), # If 'tls' is boolean, map to 'security=tls'
            "sni": proxy.get("sni"),
            "fp": proxy.get("client-fingerprint"),
            "insecure": "1" if proxy.get("skip-cert-verify") else None,
        }
        params = {k: v for k, v in params.items() if v is not None and v != ''}
        query_string = urlencode(params, quote_via=quote)
        return f"juicity://{uuid}@{server}:{port}?{query_string}#{name}"


class ConfigFetcher:
    """
    ุงู ฺฉูุงุณ ูุณุฆูู ุฏุฑุงูุช ูพฺฉุฑุจูุฏโูุง ูพุฑูฺฉุณ ุงุฒ ููุงุจุน ูุฎุชููุ
    ุงุนุชุจุงุฑุณูุฌ ุขูโูุงุ ุญุฐู ููุงุฑุฏ ุชฺฉุฑุงุฑ ู ุณุงุฒูุงูุฏู ุขูโูุง ุจุฑ ุงุณุงุณ ูพุฑูุชฺฉู ุงุณุช.
    ููฺูู ุดุงูู ููุทู ุจุฑุง ุฏุฑุงูุช ุงุทูุงุนุงุช ุฌุบุฑุงูุง IP ู ุจู ุฑูุฒ ุฑุณุงู ุขูุงุฑ ฺฉุงูุงู ุงุณุช.
    """
    def __init__(self, config: ProxyConfig):
        self.config = config
        self.validator = ConfigValidator() # ุงุณุชูุงุฏู ุงุฒ ฺฉูุงุณ ConfigValidator ุจุฑุง ุงุนุชุจุงุฑุณูุฌ
        self.protocol_counts: Dict[str, int] = {p: 0 for p in config.SUPPORTED_PROTOCOLS} # ุดูุงุฑุด ฺฉู ูพฺฉุฑุจูุฏโูุง ุจุฑ ุงุณุงุณ ูพุฑูุชฺฉู
        self.seen_configs: Set[str] = set() # ุจุฑุง ุฑุฏุงุจ ูพฺฉุฑุจูุฏโูุง ุฏุฏู ุดุฏู ู ุฌููฺฏุฑ ุงุฒ ููุงุฑุฏ ุชฺฉุฑุงุฑ
        self.channel_protocol_counts: Dict[str, Dict[str, int]] = {} # ุดูุงุฑุด ูพฺฉุฑุจูุฏโูุง ูุฑ ฺฉุงูุงู ุจุฑ ุงุณุงุณ ูพุฑูุชฺฉู
        self.session = requests.Session() # ุงุณุชูุงุฏู ุงุฒ Session ุจุฑุง ุฏุฑุฎูุงุณุชโูุง HTTP ุจู ููุธูุฑ ุญูุธ ฺฉูฺฉโูุง ู ูุฏุฑูุง
        self.session.headers.update(config.HEADERS) # ุจู ุฑูุฒ ุฑุณุงู ูุฏุฑูุง Session ุจุง ูุฏุฑูุง ูพฺฉุฑุจูุฏ
        self.ip_location_cache: Dict[str, Tuple[str, str]] = {} # ฺฉุด ุจุฑุง ุฐุฎุฑู ูููุนุช ุฌุบุฑุงูุง IPูุง


    def get_hostname_from_uri(self, uri: str) -> Optional[str]:
        """
        ูุงู ูุงุณุช (ุขุฏุฑุณ ุณุฑูุฑ) ุฑุง ุงุฒ ฺฉ URI ูพุฑูฺฉุณ ุงุณุชุฎุฑุงุฌ ูโฺฉูุฏ.
        ุจุฑุง URIโูุง Base64 ุฑูุฒฺฏุฐุงุฑ ุดุฏู (ูุงููุฏ VMess, SSR) ูุฒ ููุทู ุฎุงุต ุฏุงุฑุฏ.
        """
        try:
            if uri.lower().startswith("vmess://"):
                decoded_str = self.validator.decode_base64_text(uri[8:])
                if decoded_str:
                    try:
                        return json.loads(decoded_str).get('add')
                    except json.JSONDecodeError:
                        logger.debug(f"Failed to parse VMess JSON from: {decoded_str[:50]}...")
                        return None
            elif uri.lower().startswith("ssr://"):
                decoded_str = self.validator.decode_base64_text(uri[6:])
                if decoded_str:
                    # SSR format is typically host:port:protocol:method:obfs:base64pass/?params#name
                    # So, host is the first part before the first colon
                    return decoded_str.split(':')[0]
            else:
                # For standard URL-like URIs (vless, trojan, ss, etc.)
                return urlparse(uri).hostname
        except Exception as e:
            logger.debug(f"Error extracting hostname from URI '{uri[:80]}...': {e}")
        return None

    def batch_get_locations(self, hostnames: List[str]):
        """
        ูููุนุช ุฌุบุฑุงูุง ูุฌููุนูโุง ุงุฒ ูุงูโูุง ูุงุณุช ุง ุขุฏุฑุณโูุง IP ุฑุง ุจู ุตูุฑุช ุฏุณุชูโุง ุฏุฑุงูุช ูโฺฉูุฏ.
        ุงุฒ ุณุฑูุณ ip-api.com ุจุฑุง ุงู ฺฉุงุฑ ุงุณุชูุงุฏู ูโฺฉูุฏ ู ูุชุงุฌ ุฑุง ุฏุฑ ฺฉุด ุฐุฎุฑู ูโฺฉูุฏ.
        """
        logger.info(f"Resolving {len(hostnames)} unique hostnames to IP addresses...")
        unique_ips = set()
        hostname_to_ip_map = {}

        for hostname in hostnames:
            if not hostname or any(len(label) > 63 for label in hostname.split('.')):
                logger.warning(f"Skipping invalid hostname (e.g., label too long or empty): {hostname[:100]}...")
                self.ip_location_cache[hostname] = ("๐ณ๏ธ", "Unknown") # ูพุฑฺู ุณูุฏ ู ูุงู ฺฉุดูุฑ ูุงุดูุงุณ
                continue
            
            # Check if it's already an IP address
            is_ip = False
            try:
                socket.inet_pton(socket.AF_INET6, hostname)
                is_ip = True
            except socket.error:
                try:
                    socket.inet_pton(socket.AF_INET, hostname)
                    is_ip = True
                except socket.error:
                    is_ip = False
            
            if is_ip:
                unique_ips.add(hostname)
            else:
                # Resolve hostname to IP
                try:
                    ip = socket.gethostbyname(hostname)
                    unique_ips.add(ip)
                    hostname_to_ip_map[hostname] = ip
                except (socket.error, UnicodeEncodeError) as e:
                    logger.warning(f"Could not resolve hostname '{hostname}': {e}")
                    self.ip_location_cache[hostname] = ("๐ณ๏ธ", "Unknown") # Mark as unknown if resolution fails

        # Filter out IPs already in cache
        ips_to_query = list(unique_ips - set(self.ip_location_cache.keys()))
        if not ips_to_query:
            logger.info("All IP locations already resolved or cached. Skipping batch query.")
            return

        logger.info(f"Querying locations for {len(ips_to_query)} new IPs in batches...")
        # Split IPs into chunks for batch querying (ip-api.com limits to 100 per request)
        chunks = [ips_to_query[i:i + 100] for i in range(0, len(ips_to_query), 100)]
        
        for chunk in chunks:
            try:
                # Use POST request for batch query
                response = requests.post('http://ip-api.com/batch', json=chunk, timeout=20)
                response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
                
                for res in response.json():
                    ip_addr = res.get('query')
                    status = res.get('status')
                    if status == 'success' and res.get('countryCode'):
                        # Convert countryCode to emoji flag
                        flag = ''.join(chr(ord('๐ฆ') + ord(c.upper()) - ord('A')) for c in res['countryCode'])
                        self.ip_location_cache[ip_addr] = (flag, res['country'])
                    else:
                        self.ip_location_cache[ip_addr] = ("๐ณ๏ธ", "Unknown") # Default for failed lookups
            except requests.RequestException as e:
                logger.error(f"Batch IP location query failed: {e}")
                # Mark all IPs in the failed chunk as unknown
                for ip in chunk:
                    self.ip_location_cache[ip] = ("๐ณ๏ธ", "Unknown")
        
        # Populate cache for original hostnames using their resolved IPs
        for hostname, ip in hostname_to_ip_map.items():
            if ip in self.ip_location_cache:
                self.ip_location_cache[hostname] = self.ip_location_cache[ip]
        
        logger.info("Batch location fetching complete.")

    def get_location_from_cache(self, address: str) -> Tuple[str, str]:
        """
        ูููุนุช ุฌุบุฑุงูุง (ูพุฑฺู ุงููุฌุ ูุงู ฺฉุดูุฑ) ุฑุง ุงุฒ ฺฉุด ูููุนุชโุงุจ IP ุจุฑูโฺฏุฑุฏุงูุฏ.
        """
        return self.ip_location_cache.get(address, ("๐ณ๏ธ", "Unknown"))

    def rename_configs_with_flags(self, uris: List[str]) -> List[str]:
        """
        URIโูุง ูพุฑูฺฉุณ ุฑุง ุจุง ุงุถุงูู ฺฉุฑุฏู ูพุฑฺู ุงููุฌ ฺฉุดูุฑ ูุฑุจูุทู ุจู ูุงู ุขูโูุงุ ุชุบุฑ ูุงู ูโุฏูุฏ.
        ุงู ฺฉุงุฑ ุฎูุงูุง ู ูุฑุชุจโุณุงุฒ ูพุฑูฺฉุณโูุง ุฑุง ุขุณุงูโุชุฑ ูโฺฉูุฏ.
        """
        renamed_uris = []
        for uri in uris:
            try:
                parsed = urlparse(uri)
                hostname = self.get_hostname_from_uri(uri)
                
                if not hostname:
                    renamed_uris.append(uri)
                    continue
                
                flag, country = self.get_location_from_cache(hostname)
                original_name = unquote(parsed.fragment) or hostname # ุงุฒ ูุงู ููุฌูุฏ ุง hostname ุงุณุชูุงุฏู ูโฺฉูุฏ
                
                # ููุท ุงฺฏุฑ ูุงู ูุนู ุจุง ูพุฑฺู ุดุฑูุน ููโุดูุฏุ ูพุฑฺู ุฑุง ุงุถุงูู ฺฉูุฏ
                if not re.match(r'^[\U0001F1E6-\U0001F1FF]{2}', original_name):
                    new_name = f"{flag} {original_name}"
                else:
                    new_name = original_name # ูุงู ุงุฒ ูุจู ูพุฑฺู ุฏุงุฑุฏ
                
                # ุณุงุฎุช URI ุฌุฏุฏ ุจุง ูุงู ุชุบุฑ ุงูุชู
                new_uri = urlunparse(parsed._replace(fragment=quote(new_name, safe='')))
                renamed_uris.append(new_uri)
            except Exception as e:
                logger.warning(f"Error renaming URI with flag '{uri[:80]}...': {e}. Appending original URI.")
                renamed_uris.append(uri) # ุงฺฏุฑ ุฎุทุง ุฑุฎ ุฏุงุฏุ URI ุงุตู ุฑุง ุงุถุงูู ฺฉูุฏ
        return renamed_uris

    def fetch_with_retry(self, url: str) -> Optional[requests.Response]:
        """
        ฺฉ ุฏุฑุฎูุงุณุช HTTP GET ุฑุง ุจุง ูุงุจูุช ุชูุงุด ูุฌุฏุฏ ู ูฺฉุงูุฒู Backoff ุงูุฌุงู ูโุฏูุฏ.
        """
        backoff = 1 # ุถุฑุจ ุงูุฒุงุด ุจุฑุง ุชุงุฎุฑ
        for attempt in range(self.config.MAX_RETRIES):
            try:
                logger.debug(f"Attempt {attempt + 1} to fetch {url} (timeout: {self.config.REQUEST_TIMEOUT}s)")
                response = self.session.get(url, timeout=self.config.REQUEST_TIMEOUT)
                response.raise_for_status() # ุจุฑุง ฺฉุฏูุง ูุถุนุช 4xx/5xx ุฎุทุง ุงุฌุงุฏ ูโฺฉูุฏ
                return response
            except requests.RequestException as e:
                if attempt == self.config.MAX_RETRIES - 1:
                    logger.error(f"Failed to fetch {url} after {self.config.MAX_RETRIES} attempts: {str(e)}")
                    return None
                wait_time = min(self.config.RETRY_DELAY * backoff, 60) # ุญุฏุงฺฉุซุฑ ุชุงุฎุฑ 60 ุซุงูู
                logger.warning(f"Attempt {attempt + 1} for {url} failed, retrying in {wait_time}s: {str(e)}")
                time.sleep(wait_time)
                backoff *= 2 # ุงูุฒุงุด ููุง ุชุงุฎุฑ
        return None

    def fetch_configs_from_source(self, channel: ChannelConfig) -> List[str]:
        """
        ูพฺฉุฑุจูุฏโูุง ูพุฑูฺฉุณ ุฑุง ุงุฒ ฺฉ ฺฉุงูุงู ููุจุน ูุดุฎุต (URL) ุฏุฑุงูุช ูโฺฉูุฏ.
        ุงู ุชุงุจุน URLูุง ุนุงุฏุ ุงุดุชุฑุงฺฉโูุง Base64 ู ฺฉุงูุงูโูุง ุชูฺฏุฑุงู ุฑุง ูุฏุฑุช ูโฺฉูุฏ.
        ููฺูู ูุงูโูุง Clash YAML ุฑุง ูุฒ ูพุฑุฏุงุฒุด ูโฺฉูุฏ.
        """
        configs: List[str] = []
        channel.metrics.total_configs = 0
        channel.metrics.valid_configs = 0
        channel.metrics.protocol_counts = {p: 0 for p in self.config.SUPPORTED_PROTOCOLS} # ุจุงุฒูุดุงู ุดูุงุฑูุฏู ูพุฑูุชฺฉู ุจุฑุง ฺฉุงูุงู
        
        start_time = time.time()
        response = self.fetch_with_retry(channel.url)
        
        if not response:
            self.config.update_channel_stats(channel, False) # ุจุฑูุฒุฑุณุงู ุขูุงุฑ ฺฉุงูุงู (ูุงูููู)
            return configs # ุจุงุฒฺฏุดุช ูุณุช ุฎุงู ุฏุฑ ุตูุฑุช ุนุฏู ููููุช ุฏุฑุฎูุงุณุช
        
        response_time = time.time() - start_time
        content = response.text
        is_yaml = False

        # Attempt to parse as Clash YAML
        try:
            # Check if content looks like a YAML file (e.g., starts with specific keys)
            if content.lstrip().startswith(('proxies:', 'proxy-groups:', 'rules:', '- ')): # Added '- ' for list start
                data = yaml.safe_load(content)
                if isinstance(data, dict) and 'proxies' in data:
                    is_yaml = True
                    clash_proxies = data.get('proxies', [])
                    for proxy in clash_proxies:
                        # Convert Clash proxy dictionary back to URI
                        uri = ClashConverter.to_uri(proxy)
                        if uri:
                            configs.append(uri)
                    logger.info(f"Parsed {len(configs)} configs from Clash YAML: {channel.url}")
        except yaml.YAMLError as e:
            logger.debug(f"Content from {channel.url} is not valid YAML: {e}")
            is_yaml = False
        except Exception as e:
            logger.error(f"Error processing potential YAML from {channel.url}: {e}")
            is_yaml = False

        # If not YAML, process as plain text or Telegram channel
        if not is_yaml:
            if channel.is_telegram:
                # Scrape configurations from Telegram channel HTML
                soup = BeautifulSoup(content, 'html.parser')
                messages = soup.find_all('div', class_='tgme_widget_message_text')
                for message in messages:
                    # Extract text content and split configs
                    found_configs = self.validator.split_configs(message.get_text(separator='\n'))
                    configs.extend(found_configs)
                logger.info(f"Parsed {len(configs)} configs from Telegram channel: {channel.url}")
            else:
                # Check if content is Base64 encoded subscription link
                cleaned_content = content.strip()
                if self.validator.is_base64(cleaned_content):
                    decoded_content = self.validator.decode_base64_text(cleaned_content)
                    if decoded_content:
                        content = decoded_content # Use decoded content for splitting
                        logger.info(f"Decoded Base64 content from {channel.url}")
                
                # Split and process configs from the (possibly decoded) content
                extracted_configs = self.validator.split_configs(content)
                configs.extend(extracted_configs)
                logger.info(f"Parsed {len(extracted_configs)} configs from raw/Base64 source: {channel.url}")

        # Deduplicate and validate configs obtained from the source
        unique_configs = list(dict.fromkeys(configs)) # ุญูุธ ุชุฑุชุจ
        channel.metrics.total_configs = len(unique_configs)
        
        valid_configs = []
        for config_str in unique_configs:
            processed = self.process_config(config_str, channel)
            if processed:
                valid_configs.extend(processed)

        # Update channel statistics based on the number of valid configs found
        if len(valid_configs) >= self.config.MIN_CONFIGS_PER_CHANNEL:
            self.config.update_channel_stats(channel, True, response_time)
            logger.info(f"Channel {channel.url} successfully fetched {len(valid_configs)} valid configs.")
        else:
            self.config.update_channel_stats(channel, False, response_time)
            logger.warning(f"Channel {channel.url} yielded only {len(valid_configs)} valid configs (below min {self.config.MIN_CONFIGS_PER_CHANNEL}). Marked as failed.")

        return valid_configs

    def process_config(self, config: str, channel: ChannelConfig) -> List[str]:
        """
        ฺฉ ุฑุดุชู ูพฺฉุฑุจูุฏ ุฑุง ูพุฑุฏุงุฒุด ูโฺฉูุฏ: ุขู ุฑุง ุนุงุฏโุณุงุฒุ ุงุนุชุจุงุฑุณูุฌ ู ุฏุฑ ุตูุฑุช ููููุช
        ุจู ูุณุช ูพฺฉุฑุจูุฏโูุง ุฏุฏู ุดุฏู ู ุดูุงุฑูุฏูโูุง ูพุฑูุชฺฉู ุงุถุงูู ูโฺฉูุฏ.
        """
        processed_configs = []
        
        # ุนุงุฏโุณุงุฒ ูพุฑูุชฺฉูโูุง ูุณุชุนุงุฑ (ูุงููุฏ hy2:// ุจู hysteria2://)
        config = self.validator.normalize_hysteria2_protocol(config)
        # ูพุงฺฉุณุงุฒ ุฎุงุต ุจุฑุง Vmess
        config = self.validator.clean_vmess_config(config)
        # ูพุงฺฉุณุงุฒ ุนููู
        config = self.validator.clean_config(config)

        # ุจุฑุฑุณ ูุฑ ูพุฑูุชฺฉู ูพุดุชุจุงู ุดุฏู
        for protocol_scheme, protocol_info in self.config.SUPPORTED_PROTOCOLS.items():
            # ููุท ุงฺฏุฑ ูพฺฉุฑุจูุฏ ุจุง ุทุฑุญูุงุฑู ูพุฑูุชฺฉู ุดุฑูุน ูโุดูุฏ ู ูพุฑูุชฺฉู ูุนุงู ุงุณุช
            if config.lower().startswith(protocol_scheme) and protocol_info.get("enabled", False):
                # ุงุนุชุจุงุฑุณูุฌ ุฏูู ูพุฑูุชฺฉู
                if self.validator.validate_protocol_config(config, protocol_scheme):
                    # ุงฺฏุฑ ูพฺฉุฑุจูุฏ ุงุฒ ูุจู ุฏุฏู ูุดุฏู ุจุงุดุฏ
                    if config not in self.seen_configs:
                        self.seen_configs.add(config) # ุงุถุงูู ฺฉุฑุฏู ุจู ูุฌููุนู ูพฺฉุฑุจูุฏโูุง ุฏุฏู ุดุฏู
                        processed_configs.append(config) # ุงุถุงูู ฺฉุฑุฏู ุจู ูุณุช ูพฺฉุฑุจูุฏโูุง ูพุฑุฏุงุฒุด ุดุฏู
                        
                        # ุจู ุฑูุฒ ุฑุณุงู ุดูุงุฑูุฏูโูุง ุนููู ูพุฑูุชฺฉู
                        self.protocol_counts[protocol_scheme] = self.protocol_counts.get(protocol_scheme, 0) + 1
                        
                        # ุจู ุฑูุฒ ุฑุณุงู ุดูุงุฑูุฏูโูุง ูพุฑูุชฺฉู ุฎุงุต ฺฉุงูุงู
                        if channel.url not in self.channel_protocol_counts:
                            self.channel_protocol_counts[channel.url] = {p: 0 for p in self.config.SUPPORTED_PROTOCOLS}
                        self.channel_protocol_counts[channel.url][protocol_scheme] = \
                            self.channel_protocol_counts[channel.url].get(protocol_scheme, 0) + 1
                        
                        channel.metrics.valid_configs += 1 # ุงูุฒุงุด ุดูุงุฑูุฏู ูพฺฉุฑุจูุฏโูุง ูุนุชุจุฑ ฺฉุงูุงู
                        channel.metrics.unique_configs += 1 # ุงูุฒุงุด ุดูุงุฑูุฏู ูพฺฉุฑุจูุฏโูุง ฺฉุชุง ฺฉุงูุงู
                    else:
                        logger.debug(f"Skipping duplicate config: {config[:80]}...")
                else:
                    logger.debug(f"Config failed validation for protocol {protocol_scheme}: {config[:80]}...")
                break # ูพุณ ุงุฒ ุงูุชู ฺฉ ูพุฑูุชฺฉู ูุทุงุจูุชโุฏุงุฑุ ุงุฒ ุญููู ุฎุงุฑุฌ ุดูุฏ
        return processed_configs


    def extract_date_from_message(self, message) -> Optional[datetime]:
        """
        ุชุงุฑุฎ ุฑุง ุงุฒ ุนูุตุฑ HTML ูพุงู ุชูฺฏุฑุงู ุงุณุชุฎุฑุงุฌ ูโฺฉูุฏ.
        """
        try:
            time_element = message.find_parent('div', class_='tgme_widget_message').find('time')
            if time_element and 'datetime' in time_element.attrs:
                # ุชุจุฏู ุฑุดุชู ISO 8601 ุจู ุด datetime ู ุงุถุงูู ฺฉุฑุฏู ุงุทูุงุนุงุช ููุทูู ุฒูุงู
                return datetime.fromisoformat(time_element['datetime'].replace('Z', '+00:00'))
        except Exception as e:
            logger.debug(f"Error extracting date from message: {e}")
        return None

    def is_config_valid(self, config_text: str, date: Optional[datetime]) -> bool:
        """
        ุจุฑุฑุณ ูโฺฉูุฏ ฺฉู ุขุง ฺฉ ูพฺฉุฑุจูุฏ ุจุฑ ุงุณุงุณ ุชุงุฑุฎ ุงูุชุดุงุฑ ุขู ูููุฒ ูุนุชุจุฑ ุงุณุช ุง ุฎุฑ.
        ุงฺฏุฑ ุชุงุฑุฎ ุงุฑุงุฆู ูุดุฏู ุจุงุดุฏุ ููุดู True ุจุฑูโฺฏุฑุฏุงูุฏ.
        """
        if not date:
            return True # ุงฺฏุฑ ุชุงุฑุฎ ูุฌูุฏ ูุฏุงุฑุฏุ ูุฑุถ ูโฺฉูู ูุนุชุจุฑ ุงุณุช
        
        # ูุทูุฆู ุดูุฏ ฺฉู ุชุงุฑุฎ ุจุง ููุทูู ุฒูุงู ุขฺฏุงู ุงุณุช
        if date.tzinfo is None:
            # ุงฺฏุฑ ุชุงุฑุฎ ุจุฏูู ููุทูู ุฒูุงู ุงุณุชุ ุขู ุฑุง ุจู UTC ุชุจุฏู ฺฉูุฏ
            date = date.replace(tzinfo=timezone.utc)
        
        # ุชุงุฑุฎ ุจุฑุด (cutoff date) ุฑุง ุจุฑ ุงุณุงุณ ุญุฏุงฺฉุซุฑ ุนูุฑ ูพฺฉุฑุจูุฏ ูุญุงุณุจู ฺฉูุฏ
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=self.config.MAX_CONFIG_AGE_DAYS)
        
        return date >= cutoff_date # ุงฺฏุฑ ุชุงุฑุฎ ูพฺฉุฑุจูุฏ ุจุนุฏ ุงุฒ ุชุงุฑุฎ ุจุฑุด ุจุงุดุฏุ ูุนุชุจุฑ ุงุณุช

    def balance_protocols(self, configs: List[str]) -> Dict[str, List[str]]:
        """
        ูพฺฉุฑุจูุฏโูุง ุฑุง ุจุฑ ุงุณุงุณ ูพุฑูุชฺฉู ฺฏุฑููโุจูุฏ ู ูุชุนุงุฏู ูโฺฉูุฏ.
        ุงฺฏุฑ ุญุงูุช 'use_maximum_power' ูุนุงู ุจุงุดุฏุ ููู ูพฺฉุฑุจูุฏโูุง ุฑุง ุจุฏูู ูุญุฏูุฏุช ุจุฑูโฺฏุฑุฏุงูุฏ.
        ุฏุฑ ุบุฑ ุงู ุตูุฑุชุ ุณุน ูโฺฉูุฏ ุชุนุฏุงุฏ ูุดุฎุต ุงุฒ ูพฺฉุฑุจูุฏโูุง ุฑุง ุจุง ุงูููุชโุจูุฏ ูพุฑูุชฺฉูโูุง ุงูุชุฎุงุจ ฺฉูุฏ.
        """
        protocol_configs: Dict[str, List[str]] = {p: [] for p in self.config.SUPPORTED_PROTOCOLS}
        
        # ฺฏุฑููโุจูุฏ ูพฺฉุฑุจูุฏโูุง ุจุฑ ุงุณุงุณ ูพุฑูุชฺฉู
        for config_str in configs:
            # ุนุงุฏโุณุงุฒ ุจุฑุง ูุทุงุจูุช ุจุง ุทุฑุญูุงุฑูโูุง ุงุณุชุงูุฏุงุฑุฏ
            normalized_config = self.validator.normalize_hysteria2_protocol(config_str)
            
            for protocol_scheme in self.config.SUPPORTED_PROTOCOLS:
                if normalized_config.lower().startswith(protocol_scheme):
                    protocol_configs[protocol_scheme].append(config_str)
                    break
        
        # ุงฺฏุฑ ุญุงูุช ุญุฏุงฺฉุซุฑ ุชูุงู ูุนุงู ุงุณุช ุง ุชุนุฏุงุฏ ูพฺฉุฑุจูุฏ ูุดุฎุต ูุดุฏูุ ููู ุฑุง ุจุฑฺฏุฑุฏุงูุฏ
        if self.config.use_maximum_power or self.config.specific_config_count <= 0:
            return protocol_configs

        # ุญุงูุช ูุชุนุงุฏูโุณุงุฒ: ุงูุชุฎุงุจ ุชุนุฏุงุฏ ูุดุฎุต ูพฺฉุฑุจูุฏ
        balanced_categorized_configs: Dict[str, List[str]] = {p: [] for p in self.config.SUPPORTED_PROTOCOLS}
        total_added_configs = 0

        # ูุฑุชุจโุณุงุฒ ูพุฑูุชฺฉูโูุง ุจุฑ ุงุณุงุณ ุงูููุช (ุงูููุช ฺฉูุชุฑุ ุงูููุช ุจุงูุงุชุฑ)
        sorted_protocols = sorted(protocol_configs.keys(),
                                  key=lambda p: self.config.SUPPORTED_PROTOCOLS.get(p, {}).get("priority", 99))

        for protocol in sorted_protocols:
            if total_added_configs >= self.config.specific_config_count:
                break # ุงฺฏุฑ ุจู ุชุนุฏุงุฏ ูุฏู ุฑุณุฏูุ ูุชููู ูโุดูู

            configs_for_this_protocol = protocol_configs[protocol]
            random.shuffle(configs_for_this_protocol) # ุชุตุงุฏู ฺฉุฑุฏู ุจุฑุง ุชูุฒุน ุจูุชุฑ

            # ูุญุงุณุจู ุชุนุฏุงุฏ ุฌุงฺฏุงูโูุง ุจุงูโูุงูุฏู ู ุชุนุฏุงุฏ ูพฺฉุฑุจูุฏ ุจุฑุง ฺฏุฑูุชู ุงุฒ ุงู ูพุฑูุชฺฉู
            remaining_slots = self.config.specific_config_count - total_added_configs
            num_to_take = min(len(configs_for_this_protocol), remaining_slots)

            # ุงุทููุงู ุงุฒ ุฑุนุงุช ุญุฏุงูู ูพฺฉุฑุจูุฏ ุจุฑุง ูุฑ ูพุฑูุชฺฉู ูุนุงู
            min_for_protocol = self.config.SUPPORTED_PROTOCOLS[protocol].get("min_configs", 1)
            num_to_take = max(num_to_take, min(min_for_protocol, len(configs_for_this_protocol)))
            
            # ุงุทููุงู ุงุฒ ุนุฏู ุชุฌุงูุฒ ุงุฒ ุญุฏุงฺฉุซุฑ ูพฺฉุฑุจูุฏ ุจุฑุง ูุฑ ูพุฑูุชฺฉู
            max_for_protocol = self.config.SUPPORTED_PROTOCOLS[protocol].get("max_configs", len(configs_for_this_protocol))
            num_to_take = min(num_to_take, max_for_protocol)

            if num_to_take > 0:
                balanced_categorized_configs[protocol] = configs_for_this_protocol[:num_to_take]
                total_added_configs += num_to_take
                logger.info(f"Added {num_to_take} {protocol} configs. Total: {total_added_configs}")
        
        # ุงฺฏุฑ ูููุฒ ุฌุง ุฎุงู ุฏุงุฑูุ ูโุชูุงูู ุงุฒ ูพุฑูุชฺฉูโูุง ููุฌูุฏ ุจู ุตูุฑุช ฺุฑุฎุด ุงุถุงูู ฺฉูู
        # ุงู ุจุฎุด ุจุฑุง ุงุทููุงู ุงุฒ ุฑุณุฏู ุจู specific_config_count ุฏุฑ ุตูุฑุช ุงูฺฉุงู ุงุณุช.
        if total_added_configs < self.config.specific_config_count:
            remaining_needed = self.config.specific_config_count - total_added_configs
            all_remaining_potential_configs = []
            for protocol in sorted_protocols:
                # Add configs that were not taken in the first pass
                taken_count = len(balanced_categorized_configs[protocol])
                all_remaining_potential_configs.extend(protocol_configs[protocol][taken_count:])
            
            random.shuffle(all_remaining_potential_configs)
            # Add up to remaining_needed from the combined pool, respecting limits
            for config_str in all_remaining_potential_configs:
                if total_added_configs >= self.config.specific_config_count:
                    break
                
                # Re-identify protocol for this config
                current_protocol_scheme = None
                for p_scheme in self.config.SUPPORTED_PROTOCOLS:
                    if config_str.lower().startswith(p_scheme):
                        current_protocol_scheme = p_scheme
                        break
                
                if current_protocol_scheme:
                    max_for_current_protocol = self.config.SUPPORTED_PROTOCOLS[current_protocol_scheme].get("max_configs", float('inf'))
                    if len(balanced_categorized_configs[current_protocol_scheme]) < max_for_current_protocol:
                        balanced_categorized_configs[current_protocol_scheme].append(config_str)
                        total_added_configs += 1
        
        logger.info(f"Final balanced total configs: {total_added_configs} out of target {self.config.specific_config_count}")
        return balanced_categorized_configs


    def fetch_all_configs(self) -> Dict[str, List[str]]:
        """
        ุชูุงู ูพฺฉุฑุจูุฏโูุง ูพุฑูฺฉุณ ุฑุง ุงุฒ ุชูุงู ฺฉุงูุงูโูุง ููุจุน ูุนุงู ุฏุฑุงูุช ูโฺฉูุฏุ
        ุขูโูุง ุฑุง ูพุฑุฏุงุฒุดุ ฺฉุชุง ู ูุชุนุงุฏู ูโฺฉูุฏ ู ุณูพุณ ูููุนุช ุฌุบุฑุงูุง ุณุฑูุฑูุง ุฑุง ุฏุฑุงูุช ูโฺฉูุฏ.
        """
        all_configs: List[str] = []
        enabled_channels = self.config.get_enabled_channels()
        
        if not enabled_channels:
            logger.warning("No enabled channels found in config. Skipping fetching process.")
            return {}

        logger.info(f"Starting to fetch configs from {len(enabled_channels)} enabled channels.")
        
        for idx, channel in enumerate(enabled_channels, 1):
            logger.info(f"Fetching from {channel.url} ({idx}/{len(enabled_channels)})")
            try:
                channel_configs = self.fetch_configs_from_source(channel)
                all_configs.extend(channel_configs)
                # Update channel's protocol counts based on what was found
                channel.metrics.protocol_counts = self.channel_protocol_counts.get(channel.url, {p: 0 for p in self.config.SUPPORTED_PROTOCOLS})
            except Exception as e:
                logger.error(f"Failed to fetch or process {channel.url}: {e}", exc_info=True)
            
            # Small delay between channel fetches to be polite and avoid rate limits
            if idx < len(enabled_channels):
                time.sleep(self.config.RETRY_DELAY) # Use configured retry delay as inter-channel delay

        # Final deduplication across all channels
        unique_configs = sorted(list(dict.fromkeys(all_configs)))
        logger.info(f"Found a total of {len(unique_configs)} unique configs before balancing protocols.")

        # Balance protocols based on configuration
        balanced_configs = self.balance_protocols(unique_configs)
        
        # Collect all hostnames from the final balanced set for geo-location
        all_hostnames_to_lookup = set()
        for protocol_scheme, P_configs in balanced_configs.items():
            for uri in P_configs:
                hostname = self.get_hostname_from_uri(uri)
                if hostname:
                    all_hostnames_to_lookup.add(hostname)
        
        # Fetch locations in batch for all collected hostnames
        self.batch_get_locations(list(all_hostnames_to_lookup))
        
        # Rename configs with flags based on the fetched locations
        final_renamed_configs = {}
        for protocol, configs_list in balanced_configs.items():
            if configs_list: # Only process if there are configs for this protocol
                final_renamed_configs[protocol] = self.rename_configs_with_flags(configs_list)
        
        return final_renamed_configs

def save_configs(categorized_configs: Dict[str, List[str]], config: ProxyConfig):
    """
    ูพฺฉุฑุจูุฏโูุง ูพุฑูฺฉุณ ุฏุณุชูโุจูุฏ ุดุฏู ุฑุง ุฏุฑ ูุงูโูุง ูุชู ู Base64 ุฐุฎุฑู ูโฺฉูุฏ.
    ุดุงูู ฺฉ ูุงู ุงุตู ุชุฑฺฉุจ ุดุฏู ู ูุงูโูุง ุฌุฏุงฺฏุงูู ุจุฑุง ูุฑ ูพุฑูุชฺฉู.
    """
    try:
        output_dir = os.path.dirname(config.OUTPUT_FILE)
        os.makedirs(output_dir, exist_ok=True) # ุงุทููุงู ุงุฒ ูุฌูุฏ ุฏุงุฑฺฉุชูุฑ ุฎุฑูุฌ

        all_configs_list = [] # ูุณุช ุจุฑุง ูฺฏูุฏุงุฑ ุชูุงู ูพฺฉุฑุจูุฏโูุง ุจุฑุง ูุงู ุงุตู

        logger.info("--- Starting to save per-protocol files (text and base64) ---")
        for protocol_scheme, configs_list in categorized_configs.items():
            if not configs_list:
                continue # ุฑุฏ ฺฉุฑุฏู ูพุฑูุชฺฉูโูุง ฺฉู ูฺ ูพฺฉุฑุจูุฏ ูุฏุงุฑูุฏ

            all_configs_list.extend(configs_list) # ุงุถุงูู ฺฉุฑุฏู ุจู ูุณุช ฺฉู
            protocol_name = protocol_scheme.replace("://", "") # ูุงู ูพุฑูุชฺฉู ุจุฏูู ุทุฑุญูุงุฑู (ูุซูุงู "vless")

            # ุฐุฎุฑู ูุงู ูุชู ุจุฑุง ูุฑ ูพุฑูุชฺฉู
            protocol_filename = os.path.join(output_dir, f"{protocol_name}_configs.txt")
            try:
                with open(protocol_filename, 'w', encoding='utf-8') as f:
                    f.write('\n\n'.join(configs_list)) # ูุฑ ูพฺฉุฑุจูุฏ ุฏุฑ ฺฉ ุฎุทุ ุจุง ฺฉ ุฎุท ุฎุงู ุจู ุขูโูุง
                logger.info(f"-> SUCCESS: Saved {len(configs_list)} configs to {protocol_filename}")
            except Exception as e:
                logger.error(f"-> FAILED: Could not save protocol file {protocol_filename}: {e}")

            # ุฐุฎุฑู ูุณุฎู Base64 ุจุฑุง ูุฑ ูพุฑูุชฺฉู
            base64_filename = os.path.join(output_dir, f"{protocol_name}_configs_base64.txt")
            try:
                # ูุญุชูุง Base64 ุดุงูู ุชูุงู ูพฺฉุฑุจูุฏโูุง ุขู ูพุฑูุชฺฉู ุงุณุช ฺฉู ุจุง ุฎุท ุฌุฏุฏ ุงุฒ ูู ุฌุฏุง ุดุฏูโุงูุฏ
                base64_content = base64.b64encode('\n'.join(configs_list).encode('utf-8')).decode('utf-8')
                with open(base64_filename, 'w', encoding='utf-8') as f:
                    f.write(base64_content)
                logger.info(f"-> SUCCESS: Saved Base64 version to {base64_filename}")
            except Exception as e:
                logger.error(f"-> FAILED: Could not save Base64 file {base64_filename}: {e}")

        if not all_configs_list:
            logger.warning("No total configs to save in the main file. All categorized lists were empty.")
            return

        # ุฐุฎุฑู ูุงู ุงุตู ุชูุงู ูพฺฉุฑุจูุฏโูุง
        sorted_all_configs = sorted(list(dict.fromkeys(all_configs_list))) # ุญุฐู ููุง ููุงุฑุฏ ุชฺฉุฑุงุฑ ู ูุฑุชุจโุณุงุฒ
        
        # ูุฏุฑ ุจุฑุง ูุงู ุงุตู (ูุงุจู ุงุณุชูุงุฏู ุฏุฑ ุจุฑูุงููโูุง ฺฉูุงูุช)
        header = """//profile-title: base64:8J+RvUFub255bW91cy3wnZWP
//profile-update-interval: 1
//subscription-userinfo: upload=0; download=0; total=10737418240000000; expire=2546249531
//support-url: https://t.me/BXAMbot
//profile-web-page-url: https://github.com/4n0nymou3

"""
        with open(config.OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write(header)
            f.write('\n\n'.join(sorted_all_configs)) # ููุดุชู ูพฺฉุฑุจูุฏโูุง ุจุง ุฏู ุฎุท ุฌุฏุฏ ุจู ุขูโูุง
        logger.info(f"-> SUCCESS: Saved {len(sorted_all_configs)} total configs to {config.OUTPUT_FILE}")

        # ุฐุฎุฑู ูุณุฎู Base64 ูุงู ุงุตู
        main_base64_filename = os.path.join(output_dir, "proxy_configs_base64.txt")
        try:
            main_base64_content = base64.b64encode('\n'.join(sorted_all_configs).encode('utf-8')).decode('utf-8')
            with open(main_base64_filename, 'w', encoding='utf-8') as f:
                f.write(main_base64_content)
            logger.info(f"-> SUCCESS: Saved Base64 version of main config to {main_base64_filename}")
        except Exception as e:
            logger.error(f"-> FAILED: Could not save main Base64 file {main_base64_filename}: {e}")
    except Exception as e:
        logger.error(f"-> FAILED: A critical error occurred in save_configs function: {str(e)}", exc_info=True)


def save_channel_stats(config: ProxyConfig):
    """
    ุขูุงุฑูุง ฺฉุงูุงู ุฑุง ุฏุฑ ฺฉ ูุงู JSON ุฐุฎุฑู ูโฺฉูุฏ.
    """
    try:
        stats = {
            'timestamp': datetime.now(timezone.utc).isoformat(), # ุฒูุงู ูุนู ุจุง ููุทูู ุฒูุงู UTC
            'channels': []
        }
        for channel in config.SOURCE_URLS:
            channel_stats = {
                'url': channel.url,
                'enabled': channel.enabled,
                'metrics': {
                    'total_configs': channel.metrics.total_configs,
                    'valid_configs': channel.metrics.valid_configs,
                    'unique_configs': channel.metrics.unique_configs,
                    'avg_response_time': round(channel.metrics.avg_response_time, 2),
                    'success_count': channel.metrics.success_count,
                    'fail_count': channel.metrics.fail_count,
                    'overall_score': round(channel.metrics.overall_score, 2),
                    'last_success': channel.metrics.last_success_time.isoformat() if channel.metrics.last_success_time else None,
                    'protocol_counts': channel.metrics.protocol_counts,
                },
                'last_check_time': channel.last_check_time.isoformat() if channel.last_check_time else None, # ุงุถุงูู ุดุฏู ุฒูุงู ุขุฎุฑู ุจุฑุฑุณ
                'error_count': channel.error_count, # ุงุถุงูู ุดุฏู ุดูุงุฑูุฏู ุฎุทุง
            }
            stats['channels'].append(channel_stats)
        
        output_dir = os.path.dirname(config.STATS_FILE)
        os.makedirs(output_dir, exist_ok=True) # ุงุทููุงู ุงุฒ ูุฌูุฏ ุฏุงุฑฺฉุชูุฑ ุฎุฑูุฌ
        
        with open(config.STATS_FILE, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False) # ุฐุฎุฑู ุจู ุตูุฑุช JSON ุจุง ูุฑูุช ุฒุจุง
        logger.info(f"Channel statistics saved to {config.STATS_FILE}")
    except Exception as e:
        logger.error(f"Error saving channel statistics: {str(e)}", exc_info=True)


def main():
    """
    ุชุงุจุน ุงุตู ุจุฑุง ุงุฌุฑุง ูุฑุขูุฏ ุฏุฑุงูุชุ ูพุฑุฏุงุฒุด ู ุฐุฎุฑู ูพฺฉุฑุจูุฏโูุง ูพุฑูฺฉุณ.
    """
    try:
        # ููุฏุงุฑุฏู ุงููู ูพฺฉุฑุจูุฏโูุง
        config = ProxyConfig()
        # ููุฏุงุฑุฏู ุงููู ุฏุฑุงูุช ฺฉููุฏู ูพฺฉุฑุจูุฏโูุง
        fetcher = ConfigFetcher(config)
        
        logger.info("Starting config fetching process...")
        # ุฏุฑุงูุช ู ุฏุณุชูโุจูุฏ ุชูุงู ูพฺฉุฑุจูุฏโูุง
        categorized_configs = fetcher.fetch_all_configs()
        
        # ูุญุงุณุจู ุชุนุฏุงุฏ ฺฉู ูพฺฉุฑุจูุฏโูุง ุงูุช ุดุฏู
        total_config_count = sum(len(v) for v in categorized_configs.values())
        
        if total_config_count > 0:
            # ุฐุฎุฑู ูพฺฉุฑุจูุฏโูุง ุฏุฑ ูุงู
            save_configs(categorized_configs, config)
            logger.info(f"Successfully processed {total_config_count} configs.")
            # ฺฏุฒุงุฑุด ุชุนุฏุงุฏ ูพฺฉุฑุจูุฏโูุง ุงูุช ุดุฏู ุจุฑุง ูุฑ ูพุฑูุชฺฉู
            for protocol, configs in categorized_configs.items():
                if len(configs) > 0:
                    logger.info(f"-> Found {len(configs)} {protocol.replace('://','').upper()} configs")
        else:
            logger.warning("No valid configs found from any source! Output files will be empty or not generated.")
            # ุฏุฑ ุงู ุญุงูุชุ ููฺฉู ุงุณุช ูุงุฒ ุจุงุดุฏ ฺฉ ูุงู proxy_configs.txt ุฎุงู ุงุฌุงุฏ ุดูุฏ.
            config.save_empty_config_file()


        # ุฐุฎุฑู ุขูุงุฑ ฺฉุงูุงูโูุง
        save_channel_stats(config)
        logger.info("Process finished successfully.")

    except Exception as e:
        logger.error(f"Error in main execution: {str(e)}", exc_info=True)


if __name__ == '__main__':
    main()
